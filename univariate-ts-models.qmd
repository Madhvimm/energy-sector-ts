---
title: "Univariate TS Models (ARIMA/SARIMA)"
output: distill::distill_article
---

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: false
library(ggplot2)
library(readr)
library(tidyverse)
library(lubridate)
library(forecast)
library(tseries)
library(plotly)
library(gridExtra)
library(zoo)
library(astsa)
library(ggplot2)
library(zoo)
library(plotly)

```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Read data'
#| warning: false
#| output: false

composite_crude_oil_prices <- read.csv("data/composite_crude_oil_prices.csv")
citygate_gas_prices <- read.csv("data/citygate_gas_prices.csv")
total_electricity_prices <- read.csv("data/total_electricity_prices.csv")
gdp_data <- read.csv("data/gdp_data.csv")
cpi_data <- read.csv("data/cpi_data.csv")

```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'convert to ts'
#| warning: false
#| output: false


# For Crude Oil
composite_crude_oil_prices$Date <- as.Date(composite_crude_oil_prices$Date)
start_year <- as.numeric(format(min(composite_crude_oil_prices$Date), "%Y"))
start_month <- as.numeric(format(min(composite_crude_oil_prices$Date), "%m"))
composite_crude_oil_ts <- ts(composite_crude_oil_prices$Value, start=c(start_year, start_month), frequency=12)
# Log-transform Value
composite_crude_oil_prices$LOG_Value <- log(composite_crude_oil_prices$Value)
oil_log_ts <- ts(composite_crude_oil_prices$LOG_Value, start=c(start_year, start_month), frequency=12)

# For Natural Gas
citygate_gas_prices$Date <- as.Date(citygate_gas_prices$Date)
start_year_gas <- as.numeric(format(min(citygate_gas_prices$Date), "%Y"))
start_month_gas <- as.numeric(format(min(citygate_gas_prices$Date), "%m"))
citygate_gas_ts <- ts(citygate_gas_prices$Value, start=c(start_year_gas, start_month_gas), frequency=12)
# Log-transform Value
citygate_gas_prices$LOG_Value <- log(citygate_gas_prices$Value)
gas_log_ts <- ts(citygate_gas_prices$LOG_Value, start=c(start_year_gas, start_month_gas), frequency=12)

# For Electricity
total_electricity_prices$Date <- as.Date(total_electricity_prices$Date, format = "%Y-%m-%d")
start_year_elec <- as.numeric(format(min(total_electricity_prices$Date), "%Y"))
start_month_elec <- as.numeric(format(min(total_electricity_prices$Date), "%m"))
total_electricity_ts <- ts(total_electricity_prices$Value, start = c(start_year_elec, start_month_elec), frequency = 12)
# Log-transform Value
total_electricity_prices$LOG_Value <- log(total_electricity_prices$Value)
electricity_log_ts <- ts(total_electricity_prices$LOG_Value, start=c(start_year_elec, start_month_elec), frequency=12)


# For GDP (it's quarterly)
gdp_data$DATE <- as.Date(gdp_data$DATE, format = "%Y-%m-%d")
start_year_gdp <- as.numeric(format(min(gdp_data$DATE), "%Y"))
start_quarter_gdp <- quarter(min(gdp_data$DATE))
# Log-transform GDP
gdp_data$LOG_GDP <- log(gdp_data$GDP)
gdp_log_ts <- ts(gdp_data$LOG_GDP, start=c(start_year_gdp, start_quarter_gdp), frequency=4)


# For CPI (it's monthly)
cpi_data$DATE <- as.Date(cpi_data$DATE, format = "%Y-%m-%d")
start_year_cpi <- as.numeric(format(min(cpi_data$DATE), "%Y"))
start_month_cpi <- as.numeric(format(min(cpi_data$DATE), "%m"))
# Log-transform CPI
cpi_data$LOG_CPI <- log(cpi_data$CPIAUCSL)
cpi_log_ts <- ts(cpi_data$LOG_CPI, start = c(start_year_cpi, start_month_cpi), frequency = 12)

```

# ACF & PACF Plots

Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots are crucial tools in time series analysis, helping to identify the type of model that best describes a series. The ACF plot shows the correlation of the series with its own lags, providing insights into the overall correlation structure and potential seasonality. On the other hand, the PACF plot reveals the direct effect of past values on the current value, helping to pinpoint the order of autoregressive models.

By examining the ACF and PACF plots, we can discern patterns that suggest the presence of autoregressive (AR) or moving average (MA) components in our time series models. Significant spikes in the ACF plot indicate potential AR terms, while significant spikes in the PACF plot suggest MA terms. These plots also assist in determining the stationarity of the series, a crucial aspect in time series modeling, where non-stationary data often require differencing to achieve stationarity.

This section delves into the ACF and PACF plots for our datasets, examining their autocorrelation structures to get insights that will guide our model selection and inform our forecasting methodology.


::: panel-tabset



## Crude Oil


```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ACF-PACF Plot'
#| warning: false
#| output: true

#ACF Plot for Crude Oil
crude_oil_acf <- ggAcf(oil_log_ts) + 
  ggtitle("ACF Plot for Crude Oil (Log)") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#PACF Plot for Crude Oil
crude_oil_pacf <- ggPacf(oil_log_ts) + 
  ggtitle("PACF Plot for Crude Oil (Log)") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange the plots
grid.arrange(crude_oil_acf, crude_oil_pacf, nrow = 2)



```

The **ACF plot** for crude oil prices demonstrates prolonged significant autocorrelation, suggesting a non-stationary series. The gradual decline in correlation as lags increase indicates a potential long-term dependency or trend in the data. 

The **PACF plot** shows significant spike at lag 1 and 2, followed by non-significant values

The ACF and PACF plots suggest considering an ARIMA model with 'p' to be 1 and 2. The slow decay in the ACF implies that differencing (d > 0) may be necessary to achieve stationarity.


## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ACF-PACF Plot'
#| warning: false
#| output: true

# ACF and PACF for Natural Gas
natural_gas_acf <- ggAcf(gas_log_ts) + 
  ggtitle("ACF Plot for Natural Gas Price (Log)") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

natural_gas_pacf <- ggPacf(gas_log_ts) + 
  ggtitle("PACF Plot for Natural Gas Price (Log)") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

grid.arrange(natural_gas_acf, natural_gas_pacf, nrow = 2)


```

The **ACF plot** for natural gas prices shows a very slow decay, suggesting non-stationarity and a need for differencing. 

The **PACF plot** shows a significant spike at lag 1, followed by a drop-off.

The ACF and PACF plots suggest considering an ARIMA model with 'p' to be 1, 2 and 3. The slow decay in the ACF implies that differencing (d > 0) may be necessary to achieve stationarity.




## Electricity

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ACF-PACF Plot'
#| warning: false
#| output: true

# ACF and PACF for Electricity
electricity_acf <- ggAcf(electricity_log_ts) + 
  ggtitle("ACF Plot for Average Price of Electricity to Ultimate Customers (Log)") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

electricity_pacf <- ggPacf(electricity_log_ts) + 
  ggtitle("PACF Plot for Average Price of Electricity to Ultimate Customers (Log)") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

grid.arrange(electricity_acf, electricity_pacf, nrow = 2)


```

The **ACF plot** for electricity shows a strong positive autocorrelation across all the lags indicating a potential MA term and a need for differencing due to non-stationarity.

The **PACF plot** shows a significant correlations at lag 1. The choice of 'p' could be 1 or 2 based on the first significant spikes.

The consistent autocorrelation in the ACF plot suggests a potential need for a higher-order MA term or differencing, leading to an ARIMA(p,d,q) model consideration.



## GDP


```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ACF-PACF Plot'
#| warning: false
#| output: true

# ACF and PACF for GDP (Log)
gdp_acf <- ggAcf(gdp_log_ts) + 
  ggtitle("ACF Plot for GDP") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

gdp_pacf <- ggPacf(gdp_log_ts) + 
  ggtitle("PACF Plot for GDP") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) 

grid.arrange(gdp_acf, gdp_pacf, nrow = 2)


```


The **ACF plot** for GDP shows a persistent strong autocorrelation across all lags indicates non-stationarity, suggesting that differencing may be necessary.

The **PACF plot** have a sharp cutoff after lag 1 indicating an AR(1) process, suggesting that previous values have a significant impact on current GDP.

Given the strong autocorrelation and the PACF cutoff, an ARIMA(1,1,0) model may be a good starting point for modeling GDP, but  differencing (d > 0) may be necessary.




## CPI

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ACF-PACF Plot'
#| warning: false
#| output: true

# ACF and PACF for CPI (Log)
cpi_acf <- ggAcf(cpi_log_ts) + 
  ggtitle("ACF Plot for CPI") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

cpi_pacf <- ggPacf(cpi_log_ts) + 
  ggtitle("PACF Plot for CPI") + 
  theme_bw() +
  geom_segment(lineend = "butt", color = "#99494d") +
  geom_hline(yintercept = 0, color = "#99494d")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) 

grid.arrange(cpi_acf, cpi_pacf, nrow = 2)



```



The **ACF plot** for CPI shows a sustained high autocorrelation across lags suggests a non-stationary time series, indicative of CPI's long memory.

The **PACF plot** have a sharp spike and a cutoff after lag 1 indicating an AR(1) process, suggesting that previous values have a significant impact on current GDP.

The sustained autocorrelation in the ACF plot implies that differencing might be needed. An initial ARIMA(1,1,0) model could be considered.



## 

:::


# Detrend VS First - Difference


Detrending and differencing are foundational techniques used to render time series data stationary. **Detrending** removes the underlying trend from the data, usually by subtracting an estimated trend component from the original series. **Differencing**, in contrast, focuses on the changes between consecutive observations by transforming the series into a sequence of differences. While detrending is aimed at addressing trends, differencing is capable of eliminating both trend and seasonal components, potentially achieving stationarity in the process.

**Applying Detrending and Differencing to Our Datasets:**

Now, let's apply these critical techniques of detrending and differencing to our datasets, observing how they enhance the stationarity of the data:

::: panel-tabset


## Crude Oil


```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: false

# Convert residuals to a ts object
fit_crude_oil_log <- lm(LOG_Value ~ Date, data = composite_crude_oil_prices, na.action = NULL)

resid_crude_oil_ts_log <- ts(resid(fit_crude_oil_log), start=c(start_year, start_month), frequency=12)

```

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot the residuals
plot1_crude_oil <- autoplot(resid_crude_oil_ts_log, series="Detrended Crude Oil", colour = "#499995") + 
  theme_bw() +
  xlab("Time") +
  ylab("Residuals") +
  ggtitle("Detrended Crude Oil (Log)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Differencing plot
plot2_crude_oil <- autoplot(diff(oil_log_ts), series = "First Difference Crude Oil", colour = "#99494d") + 
  theme_bw() +
  xlab("Time") +
  ylab("Differences") +
  ggtitle("First Difference Crude Oil (Log)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange plots
grid.arrange(plot1_crude_oil, plot2_crude_oil, nrow = 2)
```

**Detrended:**

Post-detrending residuals may exhibit patterns, suggesting that linear detrending doesn’t fully capture all dynamics within the series.

**First Difference:**

The series shows fluctuations that average out around zero, suggesting enhanced stationarity. Still, a deeper autocorrelation analysis is necessary to confirm full stationarity.



## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: false

# Detrending using the original data frame
fit_natural_gas <- lm(LOG_Value ~ Date, data = citygate_gas_prices, na.action = NULL)

# Convert residuals to a ts object for plotting
resid_natural_gas_ts_log <- ts(resid(fit_natural_gas), start=c(start_year_gas, start_month_gas), frequency=12)
```


```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot the residuals
plot1_natural_gas <- autoplot(resid_natural_gas_ts_log, series="Detrended Natural Gas (Log)", colour = "#499995") + 
  theme_bw() +
  xlab("Year") +
  ylab("Residuals") +
  ggtitle("Detrended Natural Gas (Log)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Differencing plot
plot2_natural_gas <- autoplot(diff(gas_log_ts), series = "First Difference Natural Gas (Log)", colour = "#99494d") + 
  theme_bw() +
  xlab("Year") +
  ylab("Differences") +
  ggtitle("First Difference Natural Gas (Log)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange plots
grid.arrange(plot1_natural_gas, plot2_natural_gas, nrow = 2)
```


**Detrended:**

Even after detrending, the series displays volatility, implying that mere removal of a linear trend doesn't encapsulate all the complexities in the data.

**First Difference:**

The series maintains a consistent mean, though volatility persists, with noticeable spikes potentially attributable to external shocks like the 2020 pandemic.




## Electricity


```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: false

# Detrending using the original data frame
fit_electricity <- lm(LOG_Value ~ Date, data = total_electricity_prices, na.action = NULL)

# Convert residuals to a ts object for plotting
resid_electricity_ts_log <- ts(resid(fit_electricity), start=c(start_year_elec, start_month_elec), frequency=12)
```


```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot the residuals
plot1_electricity <- autoplot(resid_electricity_ts_log, series="Detrended Electricity Log", colour = "#499995") + 
  theme_bw() +
  xlab("Year") +
  ylab("Residuals") +
  ggtitle("Detrended Electricity (Log)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Differencing plot
plot2_electricity <- autoplot(diff(electricity_log_ts), series = "First Difference Electricity Log", colour = "#99494d") + 
  theme_bw() +
  xlab("Year") +
  ylab("Differences") +
  ggtitle("First Difference Electricity (Log)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange plots
grid.arrange(plot1_electricity, plot2_electricity, nrow = 2)


```


**Detrended:**

Periodic fluctuations in the detrended plot hint at seasonality within the electricity price data.

**First Difference:**

The first differenced series oscillates around a central mean, which is indicative of stationarity in the mean of the series. However, the consistent pattern of spikes indicates a strong seasonal component.




## GDP


```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: false



# Detrending using the original data frame
fit_log_gdp <- lm(LOG_GDP ~ DATE, data = gdp_data, na.action = NULL)

# Convert residuals to a ts object for plotting
resid_log_gdp_ts <- ts(resid(fit_log_gdp), start=c(start_year_gdp, start_quarter_gdp), frequency=4)

```


```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot the residuals
plot1_log_gdp <- autoplot(resid_log_gdp_ts, series="Detrended Log GDP", colour = "#499995") + 
  theme_bw() +
  xlab("Year") +
  ylab("Residuals") +
  ggtitle("Detrended Log GDP") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Differencing plot
plot2_log_gdp <- autoplot(diff(gdp_log_ts), series = "First Difference Log GDP", colour = "#99494d") + 
  theme_bw() +
  xlab("Year") +
  ylab("Differences") +
  ggtitle("First Difference Log GDP") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))


#Arrange plots
grid.arrange(plot1_log_gdp, plot2_log_gdp, nrow = 2)


```


**Detrended:**

The detrended GDP plot showcases that the residuals seem to have a non-linear component, as evidenced by the gradual decline and subsequent increase over time. The residuals decrease and then slowly begin to rise after the 1980s, accelerating significantly in recent years. GDP growth rate is not constant and a simple linear model may not be sufficient to capture the complexities.


**First Difference:**

The differenced series predominantly hovers around the zero line, which indicates that this transformation effectively removes the trend from the data, leading to a stationary series in terms of the mean. The substantial spike observed towards the end is likely due to the recent economic downturn due to the COVID-19 pandemic. 



## CPI


```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: false


# Detrending using the original data frame
fit_log_cpi <- lm(LOG_CPI ~ DATE, data = cpi_data, na.action = NULL)


# Convert residuals to a ts object for plotting
resid_log_cpi_ts <- ts(resid(fit_log_cpi), start=c(start_year_cpi, start_month_cpi), frequency=12)

```



```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot the residuals
plot1_log_cpi <- autoplot(resid_log_cpi_ts, series="Detrended Log CPI", colour = "#499995") + 
  theme_bw() +
  xlab("") +
  ylab("Residuals") +
  ggtitle("Detrended Log CPI") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))


#Differencing plot
plot2_diff_log_cpi <- autoplot(diff(cpi_log_ts), series = "First Difference Log CPI", colour = "#99494d") + 
  theme_bw() +
  xlab("Year") +
  ylab("Differences") +
  ggtitle("First Difference Log CPI") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))


#Arrange plots
grid.arrange(plot1_log_cpi, plot2_diff_log_cpi, nrow = 2)

```




**Detrended:**

A decline followed by stabilization and increase in the residuals indicates that inflationary trends are not linear over Year.


**First Difference:**

The first difference plot for CPI demonstrates a series that fluctuates around a central mean value.




##


:::


# Original Vs First Difference


This section focuses on a direct comparison between our original time series data and their first differenced forms. By examining the differences, we can highlight the effectiveness of the differencing technique in achieving stationarity—a key prerequisite for many time series modeling approaches.



::: panel-tabset



## Crude Oil

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot for the original
plot1 <- ggplot(composite_crude_oil_prices, aes(x = Date, y = LOG_Value)) + 
  geom_line(colour = "#207068") + 
  theme_bw() +
  xlab("Year") + 
  ylab("Crude Oil Prices (USD)") +
  ggtitle("Original Crude Oil Prices (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Calculate the first differences
composite_crude_oil_prices$Diff_Value <- c(NA, diff(composite_crude_oil_prices$LOG_Value))
composite_crude_oil_prices_filtered <- composite_crude_oil_prices %>% 
  filter(!is.na(Diff_Value))


#Plot for the first-differenced
plot2 <- ggplot(composite_crude_oil_prices_filtered, aes(x = Date, y = Diff_Value)) + 
  geom_line(colour = "#702028") + 
  theme_bw() +
  xlab("Year") + 
  ylab("First Differences") +
  ggtitle("First Differenced Crude Oil Data (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange
grid.arrange(plot1, plot2, nrow = 2)


```

## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot for the original
plot1_ng <- ggplot(citygate_gas_prices, aes(x = Date, y = LOG_Value)) + 
  geom_line(colour = "#207068") + 
  theme_bw() +
  xlab("Year") + 
  ylab("Natural Gas Prices") +
  ggtitle("Original Natural Gas (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Calculate the first differences
citygate_gas_prices$Diff_Value <- c(NA, diff(citygate_gas_prices$LOG_Value))
citygate_gas_prices_filtered <- citygate_gas_prices %>% 
  filter(!is.na(Diff_Value))

#Plot for the first-differenced
plot2_ng <- ggplot(citygate_gas_prices_filtered, aes(x = Date, y = Diff_Value)) + 
  geom_line(colour = "#702028") + 
  theme_bw() +
  xlab("Year") + 
  ylab("First Differences") +
  ggtitle("First Differenced Natural Gas (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# Arrange
grid.arrange(plot1_ng, plot2_ng, nrow = 2)
```



## Electricity

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot for the original
plot1_elec <- ggplot(total_electricity_prices, aes(x = Date, y = LOG_Value)) + 
  geom_line(colour = "#207068") + 
  theme_bw() +
  xlab("Year") + 
  ylab("Electricity Prices (Log)") +
  ggtitle("Original Electricity Data (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Calculate the first differences
total_electricity_prices$Diff_Value <- c(NA, diff(total_electricity_prices$LOG_Value))
total_electricity_prices_filtered <- total_electricity_prices %>% 
  filter(!is.na(Diff_Value))


#Plot for the first-differenced
plot2_elec <- ggplot(total_electricity_prices_filtered, aes(x = Date, y = Diff_Value)) + 
  geom_line(colour = "#702028") + 
  theme_bw() +
  xlab("Year") + 
  ylab("First Differences") +
  ggtitle("First Differenced Electricity Data (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange
grid.arrange(plot1_elec, plot2_elec, nrow = 2)


```


## GDP

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot for the original
plot1_gdp <- ggplot(gdp_data, aes(x = DATE, y = LOG_GDP)) + 
  geom_line(colour = "#207068") + 
  theme_bw() +
  xlab("Year") + 
  ylab("Log of GDP") +
  ggtitle("Original GDP Data (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Calculate the first differences
gdp_data$Diff_GDP <- c(NA, diff(gdp_data$LOG_GDP))
gdp_data_filtered <- gdp_data %>% 
  filter(!is.na(Diff_GDP))

#Plot for the first-differenced
plot2_gdp <- ggplot(gdp_data_filtered, aes(x = DATE, y = Diff_GDP)) + 
  geom_line(colour = "#702028") + 
  theme_bw() +
  xlab("Year") + 
  ylab("First Differences") +
  ggtitle("First Differenced GDP (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange
grid.arrange(plot1_gdp, plot2_gdp, nrow = 2)


```


## CPI

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

#Plot for the original
plot1_cpi <- ggplot(cpi_data, aes(x = DATE, y = LOG_CPI)) + 
  geom_line(colour = "#207068") + 
  theme_bw() +
  xlab("Year") + 
  ylab("CPI") +
  ggtitle("Original CPI Data (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Calculate the first differences
cpi_data$Diff_CPI <- c(NA, diff(cpi_data$LOG_CPI))
cpi_data_filtered <- cpi_data %>% 
  filter(!is.na(Diff_CPI))

#Plot for the first-differenced
plot2_cpi <- ggplot(cpi_data_filtered, aes(x = DATE, y = Diff_CPI)) + 
  geom_line(colour = "#702028") + 
  theme_bw() +
  xlab("Year") + 
  ylab("First Differences") +
  ggtitle("First Differenced CPI Data (Log)")+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

#Arrange
grid.arrange(plot1_cpi, plot2_cpi, nrow = 2)

```


## 

:::

# Adjusted Dickey-Fuller Test

After applying various transformations to address the non-stationarity in our time series data, our next step is to conduct the Adjusted Dickey-Fuller Test on the differenced data. This test is crucial for confirming that the adjustments we've made have effectively rendered the series stationary. Stationarity is a key assumption for many time series forecasting methods, as it implies that the statistical properties of the series are consistent over time. By applying the Adjusted Dickey-Fuller Test to our transformed data, we aim to validate that the mean, variance, and autocorrelation structure of the series do not change over time.

::: panel-tabset

## Crude Oil

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ADF Test'
#| warning: false
#| output: true

#First difference
diff_crude_oil_ts <- diff(oil_log_ts, differences = 1)

#Applying ADF test to the differenced time series
adf_test_diff_crude_oil <- suppressWarnings(
  adf.test(diff_crude_oil_ts, alternative = "stationary"))

#Display the test results
print(adf_test_diff_crude_oil)

```

In the adjusted test we can clearly see the p-value is significantly less than 0.05, we reject the null hypothesis and conclude that the differenced series is stationary. The fact that the differenced series is stationary (but the original was not) suggests that the crude oil prices exhibit a trend or a form of non-stationarity that can be removed by differencing. 



## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ADF Test'
#| warning: false
#| output: true

#First difference
diff_citygate_gas_ts <- diff(gas_log_ts, differences = 1)
diff_citygate_gas_ts <- na.omit(diff_citygate_gas_ts)

#Applying ADF test to the differenced time series
adf_test_diff_natural_gas <- suppressWarnings(
  adf.test(diff_citygate_gas_ts, alternative = "stationary"))

#Display the test results
adf_test_diff_natural_gas

```

In the adjusted test we can clearly see the p-value is significantly less than 0.05, leading us to reject the null hypothesis, concluding that the differenced natural gas price series is stationary. This indicates that the series, once differenced, does not have a unit root, and its mean and variance are constant over time.



## Electricity

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ADF Test'
#| warning: false
#| output: true

#First difference
diff_total_electricity_ts <- diff(electricity_log_ts, differences = 1)
diff_total_electricity_ts <- na.omit(diff_total_electricity_ts)

#Applying ADF test to the differenced time series
adf_test_diff_electricity <- suppressWarnings(
  adf.test(diff_total_electricity_ts, alternative = "stationary"))

#Display the test results
print(adf_test_diff_electricity)


```

With the p-value now below 0.05, we can reject the null hypothesis, concluding that the differenced electricity price series is stationary. This means that after differencing, the series doesn't exhibit a unit root, and its properties like mean and variance are consistent over time.



## GDP

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ADF Test'
#| warning: false
#| output: true

#First difference
diff_gdp_ts <- diff(gdp_log_ts, differences = 1)
diff_gdp_ts <- na.omit(diff_gdp_ts)

#Applying ADF test to the differenced time series
adf_test_diff_gdp <- suppressWarnings(
  adf.test(diff_gdp_ts, alternative = "stationary"))

# Display the test results
print(adf_test_diff_gdp)

```

The p-value below 0.05 allows us to reject the null hypothesis, concluding that the differenced GDP series is stationary. This suggests that the original GDP series had a trend or other non-stationary components that were effectively removed by differencing.


## CPI

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'ADF Test'
#| warning: false
#| output: true

#First difference
diff_cpi_ts <- diff(cpi_log_ts, differences = 1)
diff_cpi_ts <- na.omit(diff_cpi_ts)

#Applying ADF test to the differenced time series
adf_test_diff_cpi <- suppressWarnings(
  adf.test(diff_cpi_ts, alternative = "stationary"))

# Display the test results
print(adf_test_diff_cpi)

```

Since the p-value is now below 0.05, we can reject the null hypothesis, concluding that the differenced CPI series is stationary. 


## 

:::

After implementing the Adjusted Dickey-Fuller Test on our differenced data sets, we observed a significant reduction in the p-values for all the data sets. This result strongly suggests that the differencing process has effectively induced stationarity in these series, as indicated by the absence of a unit root. However, to ensure the robustness of our findings and to precisely model and forecast these series, a subsequent examination of the ACF and PACF plots for the differenced data is imperative. These plots will provide further insights into the autocorrelation structure of the data, guiding us in the selection of appropriate ARIMA model parameters.




# First vs Second Differencing

In time series analysis, differencing is a technique used to stabilize the mean of a series and make it stationary. When trends and seasonality are present in a time series, they can affect the predictive models. Differencing helps to mitigate these influences by focusing on the changes in the data rather than the actual values.

Differencing operates under the principle of transformation. It is designed to remove specific types of patterns:

-   First Differencing: This method subtracts the current observation from the previous one. It is a powerful tool to eliminate trends and some types of seasonality in the data, providing a clearer view of the underlying cyclical components and irregularities.

-   Second Differencing: When first differencing is not enough to achieve stationarity, or when the time series exhibits a more complex pattern such as a trend within a trend, second differencing can be employed. This involves applying the differencing operation twice, which can further simplify the predictive structure by reducing more complex serial correlations.

::: panel-tabset

## Crude Oil

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

# First Differencing
first_diff_crude_oil <- diff(oil_log_ts)
ggtsdisplay(first_diff_crude_oil, main = "First Differencing of Crude Oil Prices (Log)")

# Second Differencing
second_diff_crude_oil <- diff(first_diff_crude_oil)
ggtsdisplay(second_diff_crude_oil, main = "Second Differencing of Crude Oil Prices (Log)")
```

Based on these graphs, second differencing does not seem necessary. The first differencing appears to have sufficiently stabilized the mean of the time series, as there is no visible trend or seasonality, and the autocorrelation in the data seems to be addressed.


Examining the ACF and PACF plots for the first differencing of crude oil prices, we can suggest a range of values for p and q:

p =  1, 2, (to account for the spike at lag 1 and 2)

q = 1, 2, 3, 4 (as the first three lags are above the significance level)




## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

# First Differencing
first_diff_natural_gas <- diff(gas_log_ts)
ggtsdisplay(first_diff_natural_gas, main = "First Differencing of Natural Gas Prices (Log)")

# Second Differencing
second_diff_natural_gas <- diff(first_diff_natural_gas)
ggtsdisplay(second_diff_natural_gas, main = "Second Differencing of Natural Gas Prices (Log)")

```

We can clearly observe second differencing doesn’t appear to provide additional benefits. In fact, doing so may result in a loss of information and potentially over-differencing the data. The first difference might be sufficient for the natural gas prices time series, as the plots don't indicate non-stationarity. 


Examining the ACF and PACF plots for the first differencing of natural gas prices, we can suggest a range of values for p and q:

p = 1,2
q = 1,2 (considering the first significant lag)


## Electricity

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

# First Differencing
first_diff_electricity <- diff(electricity_log_ts)
ggtsdisplay(first_diff_electricity, main = "First Differencing of Electricity Prices (Log)")

# Second Differencing
second_diff_electricity <- diff(first_diff_electricity)
ggtsdisplay(second_diff_electricity, main = "Second Differencing of Electricity Prices (Log)")

```


It seems that first differencing might have been adequate to stabilize the mean of the series and to reduce the autocorrelation, the second differencing does not appear to provide additional necessary correction, as evidenced by the ACF and PACF plots which do not show significant autocorrelation after the first differencing.


Examining the ACF and PACF plots for the first differencing of electricity prices, we can suggest a range of values for p and q:

p = 1 to 12 (considering the significant spike at the first lag)
q = 1, 2, 3, 4, 5, 6, 7, 8, 9


## GDP

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true

# First Differencing
first_diff_gdp <- diff(gdp_log_ts)
ggtsdisplay(first_diff_gdp, main = "First Differencing of GDP")

# Second Differencing
second_diff_gdp <- diff(first_diff_gdp)
ggtsdisplay(second_diff_gdp, main = "Second Differencing of GDP")

```

The first differencing of GDP may be sufficient for stationarity, as the time series graph shows no trend and the ACF plot exhibits no significant autocorrelations.  The second differencing results indicates over-differencing, as suggested by the significant negative correlations in the ACF and PACF plots at the initial lags.

Examining the ACF and PACF plots for the first differencing of GDP, we can suggest a range of values for p and q:

p = 1, 2, 3 
q = 1, 2, 3 (considering the first few significant lags)


## CPI

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Plot'
#| warning: false
#| output: true


# First Differencing
first_diff_cpi <- diff(cpi_log_ts)
ggtsdisplay(first_diff_cpi, main = "First Differencing of CPI")

# Second Differencing
second_diff_cpi <- diff(first_diff_cpi)
ggtsdisplay(second_diff_cpi, main = "Second Differencing of CPI")

```

The second differencing of CPI doesn't show a noticeable trend, the first differencing might be sufficient. The second differencing does not seem to add further information; it rather makes the ACF and PACF plots more of a white noise process, which could suggest over-differencing.

Examining the ACF and PACF plots for the first differencing of CPI, we can suggest a range of values for p and q:

p = 1 to 12 (significant spike at lag 1)
q = 1, 2, 3, 4, 5, 6, 7, 8, 9 (to capture the initial significant lags)



## 


In our analysis, we applied first and second differencing techniques to examine their effects on stationarity. First differencing is often sufficient to stabilize the mean of a series and make it stationary. Second differencing, although sometimes necessary for complex trends, wasn't found to provide substantial benefits in our datasets. Instead, it seems to indicate a potential over-differencing, which can obscure meaningful insights from the data.

For our datasets, first differencing effectively addressed visible trends and autocorrelations, the second differencing didn't reveal additional insights and, in some cases, suggested that the data might be overly differenced, indicated by increased noise in the ACF and PACF plots. Therefore, in our case, sticking with first differencing seems to be the prudent approach to preparing our time series data for further analysis and modeling.





:::


# AIC & BIC

In time series analysis, choosing the right model is paramount for accurate forecasting. Two of the most critical metrics for model selection are the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC). Both criteria are grounded in information theory and provide a means to balance model fit with model complexity.

-   AIC is a tool for model selection that quantifies the trade-offs between model complexity (the number of parameters in the model) and the goodness of fit. AIC rewards models that achieve a high goodness of fit but penalizes those that become overly complex. A lower AIC value often indicates a preferable model.

-   BIC extends the logic of AIC by incorporating sample size into the penalty for complexity. This adjustment makes BIC more stringent with complex models when dealing with larger datasets. As with AIC, a lower BIC suggests a better model.



::: panel-tabset

## Crude Oil

p =  1, 2 (to account for the spike at lag 1 and 2)

q = 1, 2, 3, 4 

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'AIC-BIC'
#| warning: false
#| output: true


d <- 1 # Degree of differencing
temp <- data.frame()
ls <- matrix(rep(NA, 6 * 8), nrow = 8)  # 8 combinations

i <- 1
for (p in 1:2) {
  for (q in 1:4) {
    if(p-1+d+q-1<=8) {
      model <- Arima(oil_log_ts, order = c(p, d, q), include.drift = TRUE)
      ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)
      i <- i + 1
    }
  }
}

temp= as.data.frame(ls)
names(temp)= c("p","d","q","AIC","BIC","AICc")

knitr::kable(temp)


#Displaying the models with min values
temp[which.min(temp$AIC),]
temp[which.min(temp$BIC),]
temp[which.min(temp$AICc),]

```

When selecting the best ARIMA model for forecasting crude oil prices, it's common for the AIC and BIC to suggest different models. In such cases, we often prefer the model with the lower AIC. Based on the results, we've can select two models for further consideration:

- Best Model by AIC (and AICc) and BIC is : ARIMA(2,1,1)
- Second Best would be (2,1,2)



## Natural Gas

p = 1,2,3
q = 1,2 (considering the first significant lag)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'AIC-BIC'
#| warning: false
#| output: true

d <- 1 # Degree of differencing
temp <- data.frame()
ls <- matrix(rep(NA, 6 * 9), nrow = 9)  #  9 combinations: p (3 options) * q (3 options)

i <- 1
for (p in 1:3) {
  for (q in 1:3) {
    if(p-1+d+q-1<=8) {
      model <- Arima(gas_log_ts, order = c(p, d, q), include.drift = TRUE)
      ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)
      i <- i + 1
    }
  }
}

temp= as.data.frame(ls)
names(temp)= c("p","d","q","AIC","BIC","AICc")

#Displaying the table
knitr::kable(temp)


#Displaying the models with min values
temp[which.min(temp$AIC),]
temp[which.min(temp$BIC),]
temp[which.min(temp$AICc),]
```

When selecting the best ARIMA model for forecasting natural gas prices, it's common for the AIC and BIC to suggest different models. In such cases, we often prefer the model with the lower AIC. Based on the results, we've can select two models for further consideration:

- Best Model by AIC (and AICc): ARIMA(3,1,1)
- Second Best Model by BIC: ARIMA(1,1,1)




## Electricity

p = 1 to 12 (considering the significant spike at the first lag)
q = 1, 2, 3, 4, 5, 6, 7, 8, 9


```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'AIC-BIC'
#| warning: false
#| output: true

d <- 1 # Degree of differencing
temp <- data.frame()
ls <- matrix(rep(NA, 6 * 36), nrow = 36)  # p (12 options) * q (9 options) = 108 combinations - threshold

i <- 1
for (p in 1:12) {
  for (q in 1:9) {
    if(p-1+d+q-1<=8) {
      model <- Arima(electricity_log_ts, order = c(p, d, q), include.drift = TRUE)
      ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)
      i <- i + 1
    }
  }
}

temp= as.data.frame(ls)
names(temp)= c("p","d","q","AIC","BIC","AICc")

#Displaying the table
knitr::kable(temp)


#Displaying the models with min values
temp[which.min(temp$AIC),]
temp[which.min(temp$BIC),]
temp[which.min(temp$AICc),]
```




When selecting the best ARIMA model for forecasting electricity prices, it's common for the AIC and BIC to suggest different models. In such cases, we often prefer the model with the lower AIC. Based on the results, we've can select two models for further consideration:

- Best Model by AIC, BIC, and AICc (ARIMA(4,1,4))
- Second best model: ARIMA(7,1,2)




## GDP

p = 1, 2, 3 
q = 1, 2, 3 (considering the first few significant lags)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'AIC-BIC'
#| warning: false
#| output: true

d <- 1 # Degree of differencing
temp <- data.frame()
ls <- matrix(rep(NA, 6 * 9), nrow = 9)  # p (3 options) * q (3 options) = 9 combinations

i <- 1
for (p in 1:3) {
  for (q in 1:3) {
    if(p-1+d+q-1<=8) {
      model <- Arima(gdp_log_ts, order = c(p, d, q), include.drift = TRUE)
      ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)
      i <- i + 1
    }
  }
}

temp= as.data.frame(ls)
names(temp)= c("p","d","q","AIC","BIC","AICc")

#Displaying the table
knitr::kable(temp)

#Displaying the models with min values
temp[which.min(temp$AIC),]
temp[which.min(temp$BIC),]
temp[which.min(temp$AICc),]

```


When selecting the best ARIMA model for forecasting GDP, it's common for the AIC and BIC to suggest different models. In such cases, we often prefer the model with the lower AIC. Based on the results, we've can select two models for further consideration:

- Best Model by AIC, BIC and AICc: ARIMA(1,1,1)
- Second Best Model: ARIMA(3,1,2)



## CPI


p = 1 to 12 (significant spike at lag 1)
q = 1, 2, 3, 4, 5, 6, 7, 8, 9 (to capture the initial significant lags)


```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'AIC-BIC'
#| warning: false
#| output: true


d <- 1 # Degree of differencing
temp <- data.frame()
ls <- matrix(rep(NA, 6 * 36), nrow = 36)  

i <- 1
for (p in 1:12) {
  for (q in 1:9) {
    if (p-1+d+q-1<=8) {
      model <- Arima(cpi_log_ts, order = c(p, d, q), include.drift = TRUE)
      ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)
      i <- i + 1
    }
  }
}

temp= as.data.frame(ls)
names(temp)= c("p","d","q","AIC","BIC","AICc")

#Displaying the table
knitr::kable(temp)

#Displaying the models with min values
temp[which.min(temp$AIC),]
temp[which.min(temp$BIC),]
temp[which.min(temp$AICc),]

```


When selecting the best ARIMA model for forecasting CPI, it's common for the AIC and BIC to suggest different models. In such cases, we often prefer the model with the lower AIC. Based on the results, we've can select two models for further consideration:

- Best Model by AIC and AICc: ARIMA(3,1,2)
- Second Best Model: ARIMA(3,1,3)


## 

In our analysis, we used AIC and BIC to pick the best models for forecasting our data. Even though AIC and BIC sometimes suggest different models, we often chose the one with the lower AIC because it usually gives us a good balance and does a good job predicting future trends. This careful selection helps ensure our forecasts are as accurate as possible, providing valuable insights for each dataset.


:::

# Fitting ARIMA

After identifying the best models for our time series data using criteria like AIC and BIC, our next step is to fit these models to the data. Fitting the best ARIMA model allows us to refine our forecasts by honing in on the underlying patterns. While our primary focus is on the top-performing model, we also consider the second-best model. This approach gives us a fallback and an opportunity to compare, ensuring that our conclusions are robust and our forecasts are as reliable as possible.

For a general ARIMA(p, d, q) model, the equation can be represented as:

$$
x_t = \sum_{i=1}^{p} \phi_i x_{t-i} + \sum_{j=1}^{q} \theta_j w_{t-j} + w_t
$$

Here, 

- \( x_t \) represents the time series after differencing, 

- The coefficients for the autoregressive (AR) part are denoted as phi_i, where 'phi' represents the coefficients and 'i' is an index that ranges from 1 to p


- The coefficients for the moving average (MA) part are denoted as theta_j, where 'theta' represents the coefficients and 'j' is an index that ranges from 1 to q


- \( w_t \) is the error term at time \( t \).




## Fitting Best Model


::: panel-tabset

### Crude Oil

- Best Model by AIC (and AICc) and BIC is : ARIMA(2,1,1)
- Second Best would be (2,1,2)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_crudeoil <- Arima(diff(oil_log_ts), order=c(2, 1, 1),include.drift = TRUE) 
summary(fit_crudeoil)
```

**Coefficients:** The model includes two autoregressive terms (ar1, ar2) and one moving average terms, with all coefficients having significant values (based on their small standard errors (s.e.))
**Drift:** The drift coefficient is effectively zero, suggesting no consistent linear trend in the differenced series.


For the Best Model (ARIMA(2,1,1)):
Given the coefficients:

- AR1: 0.5693 
- AR2: -0.2302
- MA1: -1


The equation for the ARIMA(2,1,1) model, ignoring the drift since it's 0, would be:

$$
y_t = 0.5693y_{t-1} - 0.2302y_{t-2} + w_t - 1.0w_{t-1}
$$


### Natural Gas


- Best Model by AIC (and AICc): ARIMA(3,1,1)
- Second Best Model by BIC: ARIMA(1,1,1)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_NaturalGas <- Arima(diff(gas_log_ts), order=c(3, 1, 1),include.drift = TRUE) 
summary(fit_NaturalGas)

```


**Coefficients:** The model includes three autoregressive terms (ar1, ar2, ar3) and one moving average terms (ma1), with all coefficients having significant values.
**Drift:** The drift coefficient is effectively zero, suggesting no consistent linear trend in the differenced series.


For the Best Model (ARIMA(3,1,1)):

Given the coefficients:

- AR1: -0.2356
- AR2: -0.1575
- AR3: -0.0109
- MA1: -1.0000

The equation for the ARIMA(3,1,1) model, ignoring the drift since it's 0, would be:

$$
y_t = -0.2356y_{t-1} - 0.1575y_{t-2} - 0.0109y_{t-3} + w_t - 1.0w_{t-1}
$$




### Electricity

- Best Model by AIC, BIC, and AICc (ARIMA(4,1,4))
- Second best model: ARIMA(7,1,2)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_electricity <- Arima(diff(electricity_log_ts), order=c(4, 1, 4),include.drift = TRUE) 
summary(fit_electricity)

```

**Coefficients:** The model includes four autoregressive terms (ar1, ar2, ar3, ar4) and four moving average terms with all coefficients having significant values.
**Drift:** The drift coefficient is extremely small, suggesting a negligible linear trend in the differenced series.


For the Best Model (ARIMA(4,1,4)):

Given the coefficients:

- AR1: 2.3940
- AR2: -3.0152
- AR3: 2.0155
- AR4: -0.6215
- MA1: -2.8848
- MA2: 3.7759
- MA3: -2.7851
- MA4: 0.9013

The equation for the ARIMA(4,1,4) model:

$$
y_t = 2.3940 y_{t-1} - 3.0152 y_{t-2} + 2.0155 y_{t-3} - 0.6215 y_{t-4} + w_t - 2.8848 w_{t-1} + 3.7759 w_{t-2} - 2.7851 w_{t-3} + 0.9013 w_{t-4}
$$




### GDP

- Best Model by AIC, BIC and AICc: ARIMA(1,1,1)
- Second Best Model: ARIMA(3,1,2)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_gdp_a <- Arima(diff(gdp_log_ts), order=c(1, 1, 1),include.drift = TRUE) 
summary(fit_gdp_a)

```

**Coefficients:** The model includes one autoregressive terms (ar1) and one moving average terms (ma1), with all coefficients having significant values.
**Drift:** The drift coefficient is extremely small, suggesting a negligible linear trend in the differenced series.


For the Best Model (ARIMA(1,1,1)):

Given the coefficients:

- AR1: -0.0656
- MA1: -1.000


The equation for the ARIMA(1,1,1) model:

$$
y_t = -0.0656y_{t-1} + w_t - 1.00w_{t-1} 
$$



### CPI

- Best Model by AIC and AICc: ARIMA(3,1,2)
- Second Best Model: ARIMA(3,1,3)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_cpi_a <- Arima(diff(cpi_log_ts), order=c(3, 1, 2),include.drift = TRUE) 
summary(fit_cpi_a)

```

**Coefficients:** The model includes three autoregressive terms (ar1, ar2, ar3) and two moving average terms (ma1, ma2), with all coefficients having significant values.
**Drift:** The drift coefficient is extremely small, suggesting a negligible linear trend in the differenced series.


For the Best Model (ARIMA(3,1,2)):

Given the coefficients:

- AR1: 0.8004 
- AR2: -0.3574
- AR3: 0.1405
- MA1: -1.2473
- MA2: 0.2672

The equation for the ARIMA(3,1,2) model:

$$
y_t = 0.8004y_{t-1} - 0.3574y_{t-2} + 0.1405y_{t-3} + w_t - 1.2473w_{t-1} + 0.2672w_{t-2}
$$


## 

:::


## Fitting Second Best Model


::: panel-tabset

### Crude Oil

- Best Model by AIC (and AICc) and BIC is : ARIMA(2,1,1)
- Second Best would be (2,1,2)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_crudeoil2 <- Arima(diff(oil_log_ts), order=c(2, 1, 2),include.drift = TRUE) 
summary(fit_crudeoil2)
```


**Coefficients:** This model is simpler, with two AR and two MA parameters
**Drift:** Similar to the best model, the drift is zero.


For the Best Model (ARIMA(2,1,2)):
Given the coefficients:

- AR1: 0.9519
- AR2: -0.4028
- MA1: -1.4107 
- MA2: 0.4107 

The equation for the ARIMA(2,1,2) model, ignoring the drift since it's 0, would be:

$$
y_t = 0.9519y_{t-1} - 0.4028y_{t-2} + w_t - 1.4107w_{t-1} + 0.4107w_{t-2}
$$



#### Better Model:

- ARIMA(2,1,2) has a lower AIC (-907.19) compared to ARIMA(2,1,1) (-906.41)

- ARIMA(2,1,2) also shows a lower AICc (-906.98) than ARIMA(2,1,1) (-906.26)

- ARIMA(2,1,1) actually has a lower BIC compared to ARIMA(2,1,2)

- ARIMA(2,1,2) exhibits a higher log likelihood (459.6) compared to ARIMA(2,1,1) (458.21), indicating a slightly better fit

- ARIMA(2,1,2), both RMSE and MAE are slighlty lower than for ARIMA(2,1,1), indicating better predictive performance

- ARIMA(2,1,2) model includes an additional moving average term which seems to capture more complexity in the data dynamics


Given these considerations, the **ARIMA(2,1,2)** model is better for the series

### Natural Gas

- Best Model by AIC (and AICc): ARIMA(3,1,1)
- Second Best Model by BIC: ARIMA(1,1,1)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_NaturalGas2 <- Arima(diff(gas_log_ts), order=c(1, 1, 1),include.drift = TRUE) 
summary(fit_NaturalGas2)

```

**Coefficients:** The model includes one autoregressive terms (ar1) and one moving average terms (ma1), with all coefficients having significant values.
**Drift:** The drift coefficient is extremely small, suggesting a negligible linear trend in the differenced series.


For the Best Model (ARIMA(1,1,1)):

Given the coefficients:

- AR1: -0.2018
- MA1: -1.0


The equation for the ARIMA(1,1,1) model:

$$
x_t = - 0.2018x_{t-1} + w_t - 1.0w_{t-1}
$$

#### Better Model:


- ARIMA(3,1,1) has a lower AIC (-563.17) compared to ARIMA(1,1,1) (-557.33)

- ARIMA(3,1,1) also shows a lower AICc (-562.96) than ARIMA(1,1,1) (-557.23)

- ARIMA(1,1,1) actually has a lower BIC compared to ARIMA(3,1,1)

- ARIMA(3,1,1) exhibits a higher log likelihood (287.59) compared to ARIMA(1,1,1) (282.67), indicating a slightly better fit

- For ARIMA(3,1,1), both RMSE and MAE are slightly lower than for ARIMA(1,1,1), indicating better predictive performance

- ARIMA(3,1,1) model includes additional autoregressive terms which seem to capture more complexity in the data dynamics


Given these considerations, the **ARIMA(3,1,1)** model is deemed better for the series.




### Electricity

- Best Model by AIC, BIC, and AICc (ARIMA(4,1,4))
- Second best model: ARIMA(7,1,2)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_electricity2 <- Arima(diff(electricity_log_ts), order=c(7, 1, 2),include.drift = TRUE) 
summary(fit_electricity2)

```

**Coefficients:** The model includes seven autoregressive terms and two moving average terms (ma1, ma2), with all coefficients having significant values.
**Drift:** The drift coefficient is extremely small, suggesting a negligible linear trend in the differenced series.


For the Best Model (ARIMA(7,1,2)):

Given the coefficients:

- AR1: 0.9323
- AR2: -0.4164 
- AR3: -0.2322
- AR4: -0.1740
- AR5: 0.0383
- AR6: 0.1052
- AR7: -0.5193
- MA1: -1.7405
- MA2: 0.9597


The equation for the ARIMA(7,1,2) model:

$$
x_t = 0.9323x_{t-1} - 0.4164x_{t-2} - 0.2322x_{t-3} - 0.1740x_{t-4} + 0.0383x_{t-5} + 0.1052x_{t-6} - 0.5193x_{t-7} + w_t - 1.7405w_{t-1} + 0.9597w_{t-2}
$$

#### Better Model:

- ARIMA(7,1,2) has a lower AIC (-2250.37) compared to ARIMA(4,1,4) (-2153.26)

- ARIMA(7,1,2) also shows a lower AICc (-2249.7) than ARIMA(4,1,4) (-2152.71)

- ARIMA(7,1,2) has a lower BIC (-2206.33) compared to ARIMA(4,1,4) (-2113.23)

- ARIMA(7,1,2) exhibits a higher log likelihood (1136.19) compared to ARIMA(4,1,4) (1086.63), indicating a slightly better fit

- For ARIMA(7,1,2), both RMSE and MAE are slightly lower than for ARIMA(4,1,4), indicating better predictive performance

- ARIMA(7,1,2) includes additional autoregressive terms which seem to capture more complexity in the data dynamics


Given these considerations, the **ARIMA(7,1,2)** model is better for the series



### GDP

- Best Model by AIC, BIC and AICc: ARIMA(1,1,1)
- Second Best Model: ARIMA(3,1,2)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_gdp_a2 <- Arima(diff(gdp_log_ts), order=c(3, 1, 2),include.drift = TRUE) 
summary(fit_gdp_a2)

```


**Coefficients:** The model includes three autoregressive terms (ar1, ar2, ar3) and two moving average terms (ma1, ma2), with all coefficients having significant values.
**Drift:** The drift coefficient is extremely small, suggesting a negligible linear trend in the differenced series.


For the Best Model (ARIMA(3,1,2)):

Given the coefficients:

- AR1: 0.3440
- AR2: 0.1100
- AR3: 0.0416
- MA1: -1.4101
- MA2: 0.4101


The equation for the ARIMA(3,1,2) model:

$$
x_t = 0.3440x_{t-1} + 0.1100x_{t-2} + 0.0416x_{t-3} + w_t - 1.4101w_{t-1} + 0.4101w_{t-2} 
$$

#### Better Model:

- ARIMA(1,1,1) has a lower AIC (-780) compared to ARIMA(3,1,2) (-775.75)

- ARIMA(1,1,1) also shows a lower AICc (-779.69) than ARIMA(3,1,2) (-774.86)

- ARIMA(1,1,1) has a lower BIC (-768.41) compared to ARIMA(3,1,2) (-755.46)

- ARIMA(3,1,2) exhibits a higher log likelihood (394.87) compared to ARIMA(1,1,1) (394), indicating a slightly better fit

- Both RMSE and MAE are slightly lower for ARIMA(3,1,2), but the differences are minimal, suggesting comparable predictive performance

- ARIMA(3,1,2) includes additional autoregressive terms which seem to capture more complexity in the data dynamics



Despite the ARIMA(3,1,2) having a slightly higher log likelihood and potentially capturing more complexity, the **ARIMA(1,1,1)** model is better for the series based on lower AIC, AICc, and BIC 





### CPI

- Best Model by AIC and AICc: ARIMA(3,1,2)
- Second Best Model: ARIMA(3,1,3)

```{r, warning=FALSE, message=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: 'Fitting ARIMA'
#| warning: false
#| output: true

#Fitting ARIMA
fit_cpi_a2 <- Arima(diff(cpi_log_ts), order=c(3, 1, 3),include.drift = TRUE) 
summary(fit_cpi_a2)

```

**Coefficients:** The model includes three autoregressive terms (ar1, ar2, ar3) and three moving average terms (ma1, ma2, ma3), with all coefficients having significant values.
**Drift:** The drift coefficient is extremely small, suggesting a negligible linear trend in the differenced series.


For the Best Model (ARIMA(3,1,3)):

Given the coefficients:

- AR1: 0.0195 
- AR2: -0.6767
- AR3: 0.3641 
- MA1: -0.4767
- MA2: 0.2965 
- MA3: -0.7575


The equation for the ARIMA(3,1,3) model:

$$
x_t = 0.0195 x_{t-1} - 0.6767 x_{t-2} + 0.3641 x_{t-3} + w_t - 0.4767 w_{t-1} + 0.2965 w_{t-2} - 0.7575 w_{t-3}
$$



#### Better Model:

- ARIMA(3,1,3) has a lower AIC (-3763.69) compared to ARIMA(3,1,2) (-3757.99)

- ARIMA(3,1,3) also shows a lower AICc (-3763.33) than ARIMA(3,1,2) (-3757.71)

- ARIMA(3,1,3) has a lower BIC (-3731.6) compared to ARIMA(3,1,2) (-3729.91)

- ARIMA(3,1,3) exhibits a higher log likelihood (1889.85) compared to ARIMA(3,1,2) (1885.99), indicating a slightly better fit

- For ARIMA(3,1,3), both RMSE and MAE are slightly lower than for ARIMA(3,1,2), indicating better predictive performance

- ARIMA(3,1,3) includes an additional moving average term which seems to capture more complexity in the data dynamics, providing a slight advantage in modeling more complex patterns



Given these considerations, the **ARIMA(3,1,3)** model is better for the series




## 

:::



# Model Diagnostics



::: panel-tabset

## Crude Oil

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

set.seed(222)
diag_crudeoil <- capture.output(sarima(oil_log_ts, 2,1,2))

```


**Standardized Residuals**: The plot shows some fluctuation, but there don't appear to be any clear patterns or trends.

**ACF of Residuals**: We observe no apparent autocorrelation amongst the residuals. The absence of significant spikes outside the confidence bounds suggests that the residuals are essentially white noise

**Q-Q Plot of Std Residuals**: which assesses the normality of the residuals, shows an acceptable alignment

**Ljung-Box test**: The p-values in the plot are well above the 0.05 threshold, indicating that we fail to reject the null hypothesis of no autocorrelation among residuals at different lags. 


The diagnostic plots suggest that the ARIMA(2,1,2) model is a reasonably good fit for the data.


## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

set.seed(222)
diag_ng <- capture.output(sarima(oil_log_ts, 3,1,1))


```

**Standardized Residuals**: The plot shows some fluctuation, but there don't appear to be any clear patterns or trends.

**ACF of Residuals**: We observe no apparent autocorrelation amongst the residuals. The absence of significant spikes outside the confidence bounds suggests that the residuals are essentially white noise

**Q-Q Plot of Std Residuals**: which assesses the normality of the residuals, shows an acceptable alignment

**Ljung-Box test**: The p-values in the plot are well above the 0.05 threshold, indicating that we fail to reject the null hypothesis of no autocorrelation among residuals at different lags. 


The diagnostic plots suggest that the ARIMA(3,1,1) model is a reasonably good fit for the data.





## Electricity

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

set.seed(222)
diag_electricity <- capture.output(sarima(electricity_log_ts, 4,1,4))

```

**Standardized Residuals**: The plot shows some fluctuation, but there don't appear to be any clear patterns or trends.

**ACF of Residuals**: We do observe some apparent autocorrelation amongst the residuals. The absence of significant spikes outside the confidence bounds suggests that the residuals are essentially white noise

**Q-Q Plot of Std Residuals**: which assesses the normality of the residuals, shows an acceptable alignment

**Ljung-Box test**: The p-values in the plot are well above the 0.05 threshold, indicating that we fail to reject the null hypothesis of no autocorrelation among residuals at different lags. 


The diagnostic plots suggest that the ARIMA(2,1,2) model is a reasonably good fit for the data.





## GDP

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

set.seed(222)
diag_gdp <- capture.output(sarima(gdp_log_ts, 1,1,1))

```

**Standardized Residuals**: The plot shows some fluctuation, but there don't appear to be any clear patterns or trends.

**ACF of Residuals**: We observe no apparent autocorrelation amongst the residuals. The absence of significant spikes outside the confidence bounds suggests that the residuals are essentially white noise

**Q-Q Plot of Std Residuals**: which assesses the normality of the residuals, shows an acceptable alignment

**Ljung-Box test**: The p-values in the plot are well above the 0.05 threshold, indicating that we fail to reject the null hypothesis of no autocorrelation among residuals at different lags. 


The diagnostic plots suggest that the ARIMA(1,1,1) model is a reasonably good fit for the data.



## CPI

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

set.seed(222)
diag_cpi <- capture.output(sarima(cpi_log_ts, 3,1,3))

```


**Standardized Residuals**: The plot shows some fluctuation, but there don't appear to be any clear patterns or trends.

**ACF of Residuals**: We observe no apparent autocorrelation amongst the residuals. The absence of significant spikes outside the confidence bounds suggests that the residuals are essentially white noise

**Q-Q Plot of Std Residuals**: which assesses the normality of the residuals, shows an acceptable alignment

**Ljung-Box test**: The p-values in the plot are well above the 0.05 threshold, indicating that we fail to reject the null hypothesis of no autocorrelation among residuals at different lags. 


The diagnostic plots suggest that the ARIMA(2,1,2) model is a reasonably good fit for the data.



## 
:::

# Auto.Arima()



::: panel-tabset

## Crude Oil

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

auto.arima(oil_log_ts)

```

We used auto.arima() to pick the best model, and it chose ARIMA(2,1,0). 



## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

auto.arima(oil_log_ts)
```

## Electricity

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

auto.arima(electricity_log_ts)

```

## GDP

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

auto.arima(gdp_log_ts)

```

## CPI

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

auto.arima((cpi_log_ts))

```

## 
:::

# Forecasting



::: panel-tabset
## Crude Oil

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

fit_crudeoil2 %>% forecast(h=36) %>% autoplot()


```

## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

fit_NaturalGas %>% forecast(h=36) %>% autoplot()

```

## Electricity

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

fit_electricity %>% forecast(h=36) %>% autoplot()

```

## GDP

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

fit_gdp_a %>% forecast(h=36) %>% autoplot()

```

## CPI

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true
#| 
fit_cpi_a2 %>% forecast() %>% autoplot()

```

## 
:::


The forecasting model has designed to predict future trends for our datasets. Utilizing historical data, the model, foresee market movements up to the period we have defined, identifying patterns to craft reliable future forecasts. The predictions are visualized through the charts above, showcasing the range of possible outcomes, providing a clear, comprehensive view of upcoming market dynamics. While our model offers insightful foresight, it's built on the principle that future patterns will follow the past. 


# Comparing with Benchmark Methods



::: panel-tabset
## Crude Oil

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

autoplot(oil_log_ts) +
  autolayer(meanf(oil_log_ts, h=36),
            series="Mean", PI=FALSE) +
  autolayer(naive(oil_log_ts, h=36),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(oil_log_ts, h=36),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(oil_log_ts, h=36, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit_crudeoil2,36), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))

```

## Natural Gas

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

autoplot(gas_log_ts) +
  autolayer(meanf(gas_log_ts, h=36),
            series="Mean", PI=FALSE) +
  autolayer(naive(gas_log_ts, h=36),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(gas_log_ts, h=36),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(gas_log_ts, h=36, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit_NaturalGas,36), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))

```

## Electricity

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

autoplot(electricity_log_ts) +
  autolayer(meanf(electricity_log_ts, h=36),
            series="Mean", PI=FALSE) +
  autolayer(naive(electricity_log_ts, h=36),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(electricity_log_ts, h=36),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(electricity_log_ts, h=36, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit_electricity,36), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))

```

## GDP

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true

autoplot(gdp_log_ts) +
  autolayer(meanf(gdp_log_ts, h=36),
            series="Mean", PI=FALSE) +
  autolayer(naive(gdp_log_ts, h=36),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(gdp_log_ts, h=36),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(gdp_log_ts, h=36, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit_gdp_a,36), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))

```

## CPI

```{r, warning=FALSE, message=FALSE, echo=FALSE}
#| code-fold: true
#| code-summary: 'Importing Libraries'
#| warning: false
#| output: true
#| 

autoplot(cpi_log_ts) +
  autolayer(meanf(cpi_log_ts, h=36),
            series="Mean", PI=FALSE) +
  autolayer(naive(cpi_log_ts, h=36),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(cpi_log_ts, h=36),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(cpi_log_ts, h=36, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit_cpi_a2,36), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))

```






## 
:::



<a href="exploratory-data-analysis.qmd" class="previous-page-link" style="float: left;">&larr; Previous Page: EDA</a>




